# Awesome-Surgical-Video-Analysis

_**Under development. Welcome to contribute.**_

TO DO:
- Add paper links
- Add code links
- Add 2020/2021 works for skill assessment
- Elaborate on surgical phase/action recognition
- Elaborate on surgical instrument/scene segmentation
- More tasks

## Survey

| Title | Venue | Links |
| :--------------------: | :-------------: | :-----: |
| Surgical Data Science: from Concepts to Clinical Translation | **Arxiv 2020** | |
| Objective assessment of surgical technical skill and competency in the operating room | **ARBE 2017** | |
| Vision-based and marker-less surgical tool detection and tracking: a review of the literature | **MIA 2017** | |
| Surgical data science for next-generation interventions | **NBE 2017** | |

## Surgical Skill Assessment

| Title | Venue | Links |
| :--------------------: | :-------------: | :-----: |
| Towards Unified Surgical Skill Assessment | **CVPR 2021** | |
| Clearness of Operating Field: A Surrogate for Surgical Skills on In-Vivo Clinical Data | **IJCARS 2020** | |
| The Pros and Cons: Rank-aware Temporal Attention for Skill Determination in Long Videos | **CVPR 2019** | |
| Surgical Skill Assessment on In-Vivo Clinical Data via the Clearness of Operating Field | **MICCAI 2019** | |
| Modeling Surgical Technical Skill Using Expert Assessment for Automated Computer Rating | **AnnS 2019** | |
| Towards Optimizing Convolutional Neural Networks for Robotic Surgery Skill Evaluation | **IJCNN 2019** | |
| Video-based surgical skill assessment using 3D convolutional neural networks | **IJCARS 2019** | |
| Accurate and interpretable evaluation of surgical skills from kinematic data using fully convolutional neural networks | **IJCARS 2019** | |
| Machine learning methods for automated technical skills assessment with instructional feedback in ultrasound-guided interventions | **IJCARS 2019** | |
| Objective assessment of intraoperative technical skill in capsulorhexis using videos of cataract surgery | **IJCARS 2019** | |
| Objective classification of psychomotor laparoscopic skills of surgeons based on three different approaches | **IJCARS 2019** | |
| Who’s Better? Who’s Best? Pairwise Deep Ranking for Skill Determination | **CVPR 2018** | |
| Tool Detection and Operative Skill Assessment in Surgical Videos Using Region-Based Convolutional Neural Networks | **WACV 2018** | |
| Evaluating surgical skills from kinematic data using convolutional neural networks | **MICCAI 2018** | |
| Automated surgical skill assessment in RMIS training | **IJCARS 2018** | |
| Video and accelerometer-based motion analysis for automated surgical skills assessment | **IJCARS 2018** | |
| Deep learning with convolutional neural network for objective skill evaluation in robot-assisted surgery | **IJCARS 2018** | |
| Deep learning with convolutional neural network for objective skill evaluation in robot-assisted surgery | **IJCARS 2018** | |
| Automated robot‐assisted surgical skill evaluation: Predictive analytics approach | **IJMRCAR 2018** | |
| Meaningful Assessment of Surgical Expertise: Semantic Labeling with Data and Crowds | **MICCAI 2016** | |
| Automated video-based assessment of surgical skills for training and evaluation in medical schools | **IJCARS 2016** | |
| Task-Level vs. Segment-Level Quantitative Metrics for Surgical Skill Assessment | **Surg Educ 2016** | |
| Relative Hidden Markov Models for Video-Based Evaluation of Motion Skills in Surgical Training | **TPAMI 2015** | |
| Automated Assessment of Surgical Skills Using Frequency Analysis | **MICCAI 2015** | |
| Automated objective surgical skill assessment in the operating room from unstructured tool motion in septoplasty | **IJCARS 2015** | |
| Automated Surgical OSATS Prediction From Videos | **ISBI 2014** | |
| Pairwise Comparison-Based Objective Score for Automated Skill Assessment of Segments in a Surgical Task | **IPCAI 2014** | |
| Video Based Assessment of OSATS Using Sequential Motion Textures | **MICCAIW 2014** | |
| Augmenting Bag-of-Words: Data-Driven Discovery of Temporal and Structural Information for Activity Recognition | **CVPR 2013** | |
| String Motif-Based Description of Tool Motion for Detecting Skill and Gestures in Robotic Surgery | **MICCAI 2013** | |
| Robotic Path Planning for Surgeon Skill Evaluation in Minimally-Invasive Sinus Surgery | **MICCAI 2012** | |
| An objective and automated method for assessing surgical skill in endoscopic sinus surgery using eye-tracking and tool-motion data | **IFAR 2012** | |
| Sparse Hidden Markov Models for Surgical Gesture Classification and Skill Evaluation | **IPCAI 2012** | |
| Towards integrating task information in skills assessment for dexterous tasks in surgery and simulation | **ICRA 2011** | |
| Video-based Motion Expertise Analysis in Simulation-based Surgical Training Using Hierarchical Dirichlet Process Hidden Markov Model | **MMAR 2011** | |
| Eye Metrics as an Objective Assessment of Surgical Skill | **AnnS 2010** | |
| Surgical Task and Skill Classification from Eye Tracking and Tool Motion in Minimally Invasive Surgery | **MICCAI 2010** | |
| Task versus Subtask Surgical Skill Evaluation of Robotic Minimally Invasive Surgery | **MICCAI 2009** | |
| Data-derived models for segmentation with application to surgical assessment and training | **MICCAI 2009** | |

## Surgical Phase Recognition

| Title | Venue | Links |
| :--------------------: | :-------------: | :-----: |
| Temporal Memory Relation Network for Workflow Recognition from Surgical Video | **TMI 2021** | |
| TeCNO: Surgical Phase Recognition with Multi-Stage Temporal Convolutional Networks | **MICCAI 2020** | |
| Multi-Task Recurrent Convolutional Network with Correlation Loss for Surgical Video Analysis | **MIA 2020** | |
| LRTD: Long-Range Temporal Dependency based Active Learning for Surgical Workflow Recognition | **IJCARS 2020** | |
| Assisted phase and step annotation for surgical videos | **IJCARS 2020** | |
| Hard Frame Detection and Online Mapping for Surgical Phase Recognition | **MICCAI 2019** | |
| MS-TCN: Multi-Stage Temporal Convolutional Network for Action Segmentation | **CVPR 2019** | |
| Machine and deep learning for workflow recognition during surgery | **MITAT 2019** | |
| SV-RCNet: Workflow Recognition from Surgical Videos using Recurrent Convolutional Network | **TMI 2018** | |
| DeepPhase: Surgical Phase Recognition in CATARACTS Videos | **MICCAI 2018** | |
| Less is More: Surgical Phase Recognition with Less Annotations through Self-Supervised Pre-training of CNN-LSTM Networks | **Arxiv 2018** | |
| EndoNet: A Deep Architecture for Recognition Tasks on Laparoscopic Videos | **TMI 2017**| |
| MICCAI Workflow Challenge: Convolutional neural networks with time smoothing and Hidden Markov Model for video frames classification | **Arxiv 2016** | |
| Statistical modeling and recognition of surgical workflow | **MIA 2012** | |
| An application-dependent framework for the recognition of high-level surgical tasks in the OR | **TBE 2011** | |
| Modeling and Segmentation of Surgical Workflow from Laparoscopic Video | **MICCAI 2010** | |
| Surgical phases detection from microscope videos by combining SVM and HMM | **MICCAIW 2010** | |
| On-line recognition of surgical activity for monitoring in the operating room | **IAAI 2008** | |

## Surgical Gesture Recognition

| Title | Venue | Links |
| :--------------------: | :-------------: | :-----: |
| Relational Graph Learning on Visual and Kinematics Embeddings for Accurate Gesture Recognition in Robotic Surgery | **ICRA 2021** | |
| Automatic Gesture Recognition in Robot-assisted Surgery with Reinforcement Learning and Tree Search | **ICRA 2020** | |
| Deep Reinforcement Learning for Surgical Gesture Segmentation and Classification | **MICCAI 2018** | | 
| Unsupervised learning for surgical motion by learning to predict the future | **MICCAI 2018** | | 
| A dataset and benchmarks for segmentation and recognition of gestures in robotic surgery | **TBE 2017**| |
| Temporal Convolutional Networks for Action Segmentation and Detection | **CVPR 2017** | |
| Temporal convolutional networks: A unified approach to action segmentation | **ECCVW 2016** | |
| Recognizing surgical activities with recurrent neural networks | **MICCAI 2016** | |
| Segmental spatiotemporal cnns for fine-grained action segmentation | **ECCV 2016** | |
| Learning convolutional action primitives for fine-grained action recognition | **ICRA 2016** | |
| An improved model for segmentation and recognition of fine-grained activities with application to surgical training tasks | **WACV 2015** | |
| Learning shared, discriminative dictionaries for surgical gesture segmentation and classification | **MICCAIW 2015** | |
| JHU-ISI gesture and skill assessment working set (JIGSAWS): A surgical activity dataset for human motion modeling | **MICCAIW 2014**| |
| Surgical gesture segmentation and recognition | **MICCAI 2013** | |
| Sparse hidden markov models for surgical gesture classification and skill evaluation | **IPCAI 2011** | |
| Data-derived models for segmentation with application to surgical assessment and training | **MICCAI 2009** | |
| Automatic detection and segmentation of robot-assisted surgical motions | **MICCAI 2005** | |


## Surgical Instrument Segmentation / Tracking / Detection

| Title | Venue | Links |
| :--------------------: | :-------------: | :-----: |
| One to Many: Adaptive Instrument Segmentation via Meta Learning and Dynamic Online Adaptation in Robotic Surgical Video | **ICRA 2021** | |
| Unsupervised Surgical Instrument Segmentation via Anchor Generation and Semantic Diffusion | **MICCAI 2020** | |
| Learning Motion Flows for Semi-supervised Instrument Segmentation from Robotic Surgical Video| **MICCAI 2020** | |
| Automated Surgical Instrument Detection from Laparoscopic Gastrectomy Video Images Using an Open Source Convolutional Neural Network Platform | **JACS 2020** | |
| BARNet: Bilinear Attention Network with Adaptive Receptive Field for Surgical Instrument Segmentation | **Arxiv 2020** | |
| Incorporating Temporal Prior from Motion Flow for Instrument Segmentation in Minimally Invasive Surgery Video | **MICCAI 2019**| |
| Weakly supervised convolutional {LSTM} approach for tool tracking in laparoscopic videos | **IJCARS 2019** | |
| Self-supervised surgical tool segmentation using kinematic information | **ICRA 2019** | |
| Learning Where to Look While Tracking Instruments in Robot-assisted Surgery | **MICCAI 2019** | |
| Deep residual learning for instrument segmentation in robotic surgery | **MLMI 2019** | |
| 2017 robotic instrument segmentation challenge | **Arxiiv 2019** | |
| U-NetPlus: A Modified Encoder-Decoder U-Net Architecture for Semantic and Instance Segmentation of Surgical Instruments from Laparoscopic Images | **EMBC 2019**| |
| RASNet: Segmentation for tracking surgical instruments in surgical videos using refined attention segmentation network | **EMBC 2019** | |
| CFCM: Segmentation via coarse to fine context memory | **MICCAI 2018** | |
| Exploiting the potential of unlabeled endoscopic video data with self-supervised learning | **IJCARS 2018** | |
| Weakly-supervised learning for tool localization in laparoscopic videos | **MICCAIW 2018** | |
| Automatic instrument segmentation in robot-assisted surgery using deep learning | **ICMLA 2018** | |
| Concurrent segmentation and localization for tracking of surgical instruments | **MICCAI 2017** | |
| Toolnet: holistically-nested real-time segmentation of robotic surgical tools | **IROS 2017** | |
| Real-time localization of articulated surgical instruments in retinal microsurgery | **MIA 2016** | |
| Detecting surgical tools by modelling local appearance and global shape | **TMI 2015** | |
| Visual tracking of da vinci instruments for laparoscopic surgery | **MI 2014**| |


## Surgical Instrument Presence Recognition

| Title | Venue | Links |
| :--------------------: | :-------------: | :-----: |
| Multi-Task Recurrent Convolutional Network with Correlation Loss for Surgical Video Analysis | **MIA 2020** | |
| CATARACTS: Challenge on automatic tool annotation for cataRACT surgery | **MIA 2019** | |

## Surgical Scene Segmentation


<!-- 
@article{2017Arxiv,
  title={Unsupervised temporal context learning using convolutional neural networks for laparoscopic workflow analysis},
  author={Bodenstedt, Sebastian and Wagner, Martin and Kati{\'c}, Darko and Mietkowski, Patrick and Mayer, Benjamin and Kenngott, Hannes and M{\"u}ller-Stich, Beat and Dillmann, R{\"u}diger and Speidel, Stefanie},
  journal={arXiv:1702.03684},
  year={2017}
} -->

